{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-03T04:58:47.739430Z",
     "start_time": "2021-07-03T04:58:40.353072Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-13T17:01:18.730631Z",
     "iopub.status.busy": "2021-06-13T17:01:18.730276Z",
     "iopub.status.idle": "2021-06-13T17:01:20.535109Z",
     "shell.execute_reply": "2021-06-13T17:01:20.534047Z",
     "shell.execute_reply.started": "2021-06-13T17:01:18.730555Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        continue\n",
    "import joblib\n",
    "import numpy as np\n",
    "from smartapi import SmartConnect\n",
    "from rich import  print\n",
    "from smartapi import SmartWebSocket\n",
    "import ipywidgets as widgets\n",
    "import json\n",
    "import pandas as pd\n",
    "pd.set_option('plotting.backend', 'pandas_bokeh')\n",
    "import pandas_bokeh\n",
    "pandas_bokeh.output_notebook()\n",
    "import datetime\n",
    "import threading\n",
    "import ast \n",
    "import http.client\n",
    "import mimetypes\n",
    "conn = http.client.HTTPSConnection(\"apiconnect.angelbroking.com\")\n",
    "import time\n",
    "from dateutil import parser, tz\n",
    "from tqdm import tqdm\n",
    "import nsepython\n",
    "\n",
    "obj=SmartConnect(api_key=\"ANGEL_HISTORICAL_DATA_API_KEY\",\n",
    "                #access_token = \"your access token\",\n",
    "                #refresh_token = \"your refresh_token\"\n",
    "                )\n",
    "\n",
    "data = obj.generateSession(\"ANGEL_CLIENT_ID\",\"ANGEL_PASSWORD\")\n",
    "refreshToken= data['data']['refreshToken']\n",
    "feedToken=obj.getfeedToken()\n",
    "userProfile= obj.getProfile(refreshToken)\n",
    "\n",
    "headers = {\n",
    "  'Authorization': f'Bearer {obj.access_token}',\n",
    "  'Content-Type': 'application/json',\n",
    "  'Accept': 'application/json',\n",
    "  'X-UserType': 'USER',\n",
    "  'X-SourceID': 'WEB',\n",
    "  'X-ClientLocalIP': obj.clientLocalIP,\n",
    "  'X-ClientPublicIP': obj.clientPublicIP,\n",
    "  'X-MACAddress': obj.clientMacAddress,\n",
    "  'X-PrivateKey': obj.api_key\n",
    "}\n",
    "\n",
    "print (f\"LOGIN : {userProfile['data']['name']}\")\n",
    "\n",
    "calculate_loss_over_all_values = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-21T05:42:41.844586Z",
     "start_time": "2021-06-21T05:42:41.702255Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-13T17:01:20.599785Z",
     "iopub.status.busy": "2021-06-13T17:01:20.599116Z",
     "iopub.status.idle": "2021-06-13T17:01:20.733433Z",
     "shell.execute_reply": "2021-06-13T17:01:20.732410Z",
     "shell.execute_reply.started": "2021-06-13T17:01:20.599741Z"
    }
   },
   "outputs": [],
   "source": [
    "input_window = 300\n",
    "output_window = 5\n",
    "batch_size = 10 # batch size\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()       \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        #pe.requires_grad = False\n",
    "        self.register_buffer('pe', pe)\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n",
    "\n",
    "class TransAm(nn.Module):\n",
    "    def __init__(self,feature_size=30,num_layers=2,dropout=0.2):\n",
    "        super(TransAm, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(feature_size)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=feature_size, nhead=10, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)        \n",
    "        self.decoder = nn.Linear(feature_size,1)\n",
    "        self.init_weights()\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1    \n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "    def forward(self,src):\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "            self.src_mask = mask\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src,self.src_mask)#, self.src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "def create_inout_sequences(input_data, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        train_seq = np.append(input_data[i:i+tw][:-output_window] , output_window * [0])\n",
    "        train_label = input_data[i:i+tw]\n",
    "        #train_label = input_data[i+output_window:i+tw+output_window]\n",
    "        inout_seq.append((train_seq ,train_label))\n",
    "    return torch.FloatTensor(inout_seq)\n",
    "\n",
    "\n",
    "def get_data2(inst):\n",
    "    global scaler\n",
    "    old_lst=[]\n",
    "    interval='5minute'\n",
    "    todaydt=datetime.date.today()\n",
    "    hud_ago=todaydt-datetime.timedelta(days=50) #59\n",
    "    to_date=datetime.date.isoformat(todaydt)\n",
    "    from_date=datetime.date.isoformat(hud_ago)\n",
    "\n",
    "    for i2 in range(1):\n",
    "        new_lst = module.kite.historical_data(inst, from_date, to_date, interval,continuous=False)\n",
    "        old_lst = new_lst + old_lst\n",
    "        todaydt=todaydt-datetime.timedelta(days=51) #60\n",
    "        hud_ago=hud_ago-datetime.timedelta(days=51) #60\n",
    "        to_date=datetime.date.isoformat(todaydt)\n",
    "        from_date=datetime.date.isoformat(hud_ago)\n",
    "    df=pd.DataFrame(old_lst)\n",
    "    df_nifty = df\n",
    "    this_inst_df = df_nifty\n",
    "    amplitude = this_inst_df['close'].to_numpy()[-905:]\n",
    "    amplitude = amplitude.reshape(-1)\n",
    "    scaler = MinMaxScaler(feature_range=(-15, 15)) \n",
    "    amplitude = scaler.fit_transform(amplitude.reshape(-1, 1)).reshape(-1)\n",
    "    sampels = int(amplitude.shape[0]*0)\n",
    "    train_data = amplitude[:sampels]\n",
    "    test_data = amplitude\n",
    "    train_sequence = create_inout_sequences(train_data,input_window)\n",
    "    train_sequence = train_sequence[:-output_window]\n",
    "    test_data = create_inout_sequences(test_data,input_window)\n",
    "    test_data = test_data[:-output_window]\n",
    "    return train_sequence.to(device),test_data.to(device)\n",
    "def get_batch(source, i,batch_size):\n",
    "    seq_len = min(batch_size, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]    \n",
    "    input = torch.stack(torch.stack([item[0] for item in data]).chunk(input_window,1)) # 1 is feature size\n",
    "    target = torch.stack(torch.stack([item[1] for item in data]).chunk(input_window,1))\n",
    "    return input, target\n",
    "def evaluate(eval_model, data_source):\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    eval_batch_size = 1000\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(data_source) - 1, eval_batch_size):\n",
    "            data, targets = get_batch(data_source, i,eval_batch_size)\n",
    "            output = eval_model(data)            \n",
    "            if calculate_loss_over_all_values:\n",
    "                total_loss += len(data[0])* criterion(output, targets).to(device).item()\n",
    "            else:                                \n",
    "                total_loss += len(data[0])* criterion(output[-output_window:], targets[-output_window:]).to(device).item()            \n",
    "    return total_loss / len(data_source)\n",
    "\n",
    "plot_counter = 0\n",
    "def plot_and_loss(eval_model, data_source,epoch,tknip):\n",
    "    global plot_counter\n",
    "    eval_model.eval() \n",
    "    total_loss = 0.\n",
    "    test_result = torch.Tensor(0)    \n",
    "    truth = torch.Tensor(0)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(data_source) - 1):\n",
    "            data, target = get_batch(data_source, i,1)\n",
    "            # look like the model returns static values for the output window\n",
    "            output = eval_model(data)    \n",
    "            if calculate_loss_over_all_values:                                \n",
    "                total_loss += criterion(output, target).item()\n",
    "            else:\n",
    "                total_loss += criterion(output[-output_window:], target[-output_window:]).item()\n",
    "\n",
    "            test_result = torch.cat((test_result.to(device), output[-1].view(-1).to(device)), 0) #todo: check this. -> looks good to me\n",
    "            truth = torch.cat((truth.to(device), target[-1].view(-1).to(device)), 0)\n",
    "    test_result = test_result.cpu().numpy()\n",
    "    truth = truth.cpu().numpy()\n",
    "    len(test_result)\n",
    "    return total_loss / i\n",
    "\n",
    "\n",
    "def predict_future_open(eval_model, data_source,steps,tkn):\n",
    "    eval_model.eval() \n",
    "    total_loss = 0.\n",
    "    test_result = torch.Tensor(0)    \n",
    "    truth = torch.Tensor(0)\n",
    "    _ , data = get_batch(data_source, 0,1)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, steps,1):\n",
    "            input = torch.clone(data[-input_window:])\n",
    "            input[-output_window:] = 0     \n",
    "            output = eval_model(data[-input_window:])                        \n",
    "            data = torch.cat((data, output[-1:]))\n",
    "    data = data.cpu().view(-1)\n",
    "    pyplot.plot(data,color=\"red\")       \n",
    "    pyplot.plot(data[:input_window],color=\"blue\")\n",
    "    pyplot.grid(True, which='both')\n",
    "    pyplot.axhline(y=0, color='k')\n",
    "    return data\n",
    "\n",
    "def predict_future(eval_model, data_source,steps,tkn):\n",
    "    eval_model.eval() \n",
    "    total_loss = 0.\n",
    "    test_result = torch.Tensor(0)    \n",
    "    truth = torch.Tensor(0)\n",
    "    _ , data = get_batch(data_source, 0,1)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, steps,1):\n",
    "            input = torch.clone(data[-input_window:])\n",
    "            input[-output_window:] = 0     \n",
    "            output = eval_model(data[-input_window:])                        \n",
    "            data = torch.cat((data, output[-1:]))\n",
    "    data = data.cpu().view(-1)\n",
    "    pyplot.plot(data,color=\"red\")       \n",
    "    pyplot.plot(data[:input_window],color=\"blue\")\n",
    "    pyplot.grid(True, which='both')\n",
    "    pyplot.axhline(y=0, color='k')\n",
    "    pyplot.savefig(f'./nmnm/transformer-future_{plot_counter}_{steps}_{tkn}.png')\n",
    "    pyplot.close()\n",
    "        \n",
    "model= torch.load('./best_model_multi8.pt',map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T11:43:44.668487Z",
     "start_time": "2021-06-20T11:43:44.665872Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_data, val_data = get_data2(2029825)\n",
    "# predict_future(model,val_data,2000,2029825)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T11:43:44.692422Z",
     "start_time": "2021-06-20T11:43:44.688092Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# look_up = 1001\n",
    "\n",
    "# inst_check_list = [1793,5633,6401,3861249,2995969,25601,325121,6483969,40193,41729,54273,\n",
    "#                    60417,5436929,70401,1510401,4267265,4268801]\n",
    "\n",
    "# for one in tqdm(inst_check_list):\n",
    "#     train_data, val_data = get_data2(one)\n",
    "#     col_list = []\n",
    "\n",
    "#     orig_data = np.array([])\n",
    "#     orig_data\n",
    "\n",
    "#     for one_part_point in range(15):   #  total_parts\n",
    "#     #     print(val_data[-(300*(one_part_point+1))::].shape)\n",
    "#         dpp = predict_future_open(model, val_data[-(300*(one_part_point+1))::],2000,123123)\n",
    "\n",
    "#         col_list.append(np.append(orig_data,dpp))\n",
    "\n",
    "#         orig_data = np.append(orig_data,dpp[:input_window])\n",
    "\n",
    "#     #     col_list.append(dpp)\n",
    "#     col_list.append(orig_data)\n",
    "#     pyplot.savefig(f'./nmnm/test_plot.png')\n",
    "#     pyplot.close()\n",
    "\n",
    "#     plot_df = pd.DataFrame(col_list)\n",
    "#     trps = plot_df.transpose()\n",
    "#     trps.plot()\n",
    "#     pd.DataFrame(orig_data).plot()\n",
    "    \n",
    "    \n",
    "# #     predict_future(model,val_data,look_up,one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T03:45:11.226541Z",
     "start_time": "2021-06-16T03:45:09.970313Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-21T05:10:10.246678Z",
     "start_time": "2021-06-21T05:09:52.057Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col_list = []\n",
    "orig_data = np.array([])\n",
    "test_len = 15\n",
    "\n",
    "for one_part_point in tqdm(range(test_len)):   #  total_parts\n",
    "    dpp = predict_future_open(model, val_data[input_window*(one_part_point):input_window*(one_part_point+1)],1000,123123)\n",
    "    col_list.append(np.append(orig_data,dpp))\n",
    "    orig_data = np.append(orig_data,dpp[:input_window])\n",
    "\n",
    "col_list.append(orig_data)\n",
    "pyplot.savefig(f'./nmnm/test_plot.png')\n",
    "pyplot.close()\n",
    "\n",
    "plot_df = pd.DataFrame(col_list)\n",
    "trps = plot_df.transpose()\n",
    "trps.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T09:22:36.231937Z",
     "start_time": "2021-06-16T09:22:36.228276Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for jj in range(8):\n",
    "#     print(jj+1)\n",
    "#     model= torch.load(f'./best_model_multi{jj+1}.pt',map_location=torch.device('cpu'))\n",
    "    \n",
    "#     col_list = []\n",
    "#     orig_data = np.array([])\n",
    "#     test_len = 8\n",
    "\n",
    "#     for one_part_point in tqdm(range(test_len)):   #  total_parts\n",
    "#         dpp = predict_future_open(model, val_data[input_window*(one_part_point):input_window*(one_part_point+1)],100,123123)\n",
    "#         col_list.append(np.append(orig_data,dpp))\n",
    "#         orig_data = np.append(orig_data,dpp[:input_window])\n",
    "\n",
    "#     col_list.append(orig_data)\n",
    "#     pyplot.savefig(f'./nmnm/test_plot.png')\n",
    "#     pyplot.close()\n",
    "\n",
    "#     plot_df = pd.DataFrame(col_list)\n",
    "#     trps = plot_df.transpose()\n",
    "#     trps.plot()\n",
    "#     print('*'*60)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-21T05:10:20.396484Z",
     "start_time": "2021-06-21T05:10:19.335324Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data, val_data = get_data2(3356417)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-19T12:41:52.823953Z",
     "start_time": "2021-06-19T12:41:52.814844Z"
    }
   },
   "outputs": [],
   "source": [
    "val_data[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-21T06:51:14.766047Z",
     "start_time": "2021-06-21T06:50:46.100703Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data, val_data = get_data2(3529217)\n",
    "col_list = []\n",
    "orig_data = np.array([])\n",
    "test_len = 2\n",
    "model= torch.load(f'./best_model_multi18.pt',map_location=torch.device('cpu'))\n",
    "for one_part_point in tqdm(range(test_len)):   #  total_parts\n",
    "    dpp = predict_future_open(model, val_data[input_window*(one_part_point):input_window*(one_part_point+1)],\n",
    "                              1000,123123)\n",
    "    mod = dpp[0].numpy()\n",
    "    if (orig_data.size != 0): #check not empty\n",
    "        org = orig_data[-1]\n",
    "        diff = org-mod\n",
    "        dpp = dpp + diff\n",
    "\n",
    "    col_list.append(np.append(orig_data,dpp))\n",
    "    orig_data = np.append(orig_data,dpp[:input_window])\n",
    "\n",
    "pyplot.savefig(f'./nmnm/test_plot.png')\n",
    "pyplot.close()\n",
    "\n",
    "plot_df = pd.DataFrame(col_list)\n",
    "trps = plot_df.transpose()\n",
    "trps.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-21T06:58:47.728113Z",
     "start_time": "2021-06-21T06:58:11.353991Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data, val_data = get_data2(3356417)  #3529217\n",
    "col_list = []\n",
    "orig_data = np.array([])\n",
    "test_len = 2\n",
    "model= torch.load(f'./best_model_multi18.pt',map_location=torch.device('cpu'))\n",
    "for one_part_point in tqdm(range(test_len)):   #  total_parts\n",
    "    dpp = predict_future_open(model, val_data[input_window*(one_part_point):input_window*(one_part_point+1)],\n",
    "                              1000,123123)\n",
    "    if (orig_data.size != 0): #check not empty\n",
    "        diff = orig_data[-1] - dpp[301].numpy()\n",
    "        dpp = dpp - diff\n",
    "\n",
    "    col_list.append(np.append(orig_data,dpp))\n",
    "    orig_data = np.append(orig_data,dpp[:input_window])\n",
    "\n",
    "pyplot.savefig(f'./nmnm/test_plot.png')\n",
    "pyplot.close()\n",
    "\n",
    "plot_df = pd.DataFrame(col_list)\n",
    "trps = plot_df.transpose()\n",
    "trps.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T01:53:05.537796Z",
     "start_time": "2021-06-18T01:42:10.655185Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(14,19):\n",
    "    for jj in [1459457,70401,261889,]:\n",
    "#     for jj in [3861249,6401,3677697,3669505]:\n",
    "        print('*'*50)\n",
    "        print(i)\n",
    "        print(jj)\n",
    "        \n",
    "        train_data, val_data = get_data2(jj)\n",
    "        col_list = []\n",
    "        orig_data = np.array([])\n",
    "        test_len = 6\n",
    "        model= torch.load(f'./best_model_multi{i}.pt',map_location=torch.device('cpu'))\n",
    "        for one_part_point in tqdm(range(test_len)):   #  total_parts\n",
    "            dpp = predict_future_open(model, val_data[input_window*(one_part_point):input_window*(one_part_point+1)],\n",
    "                                      300,123123)\n",
    "            mod = dpp[0].numpy()\n",
    "            if (orig_data.size != 0): #check not empty\n",
    "                org = orig_data[-1]\n",
    "                diff = org-mod\n",
    "                dpp = dpp + diff\n",
    "\n",
    "            col_list.append(np.append(orig_data,dpp))\n",
    "            orig_data = np.append(orig_data,dpp[:input_window])\n",
    "\n",
    "        pyplot.savefig(f'./nmnm/test_plot.png')\n",
    "        pyplot.close()\n",
    "\n",
    "        plot_df = pd.DataFrame(col_list)\n",
    "        trps = plot_df.transpose()\n",
    "        trps.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-19T04:15:42.695654Z",
     "start_time": "2021-06-19T04:15:22.902983Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_df = pd.read_excel('../valid_loss_map_df_5x (17).xlsx')\n",
    "loss_df['name'] =''\n",
    "type(loss_df['inst'][0])\n",
    "all_inst = pd.read_excel('./all_inst.xlsx')\n",
    "df3 = pd.merge(loss_df,all_inst,left_on=['inst'], right_on = ['instrument_token'], how = 'left')\n",
    "df3['ltp']=0.0\n",
    "df3 = df3[0:143]\n",
    "inedx_counter = 0\n",
    "for one_symbol in tqdm(df3.tradingsymbol):\n",
    "    ltp = module.kite.quote([f'NSE:{one_symbol}'])[f'NSE:{one_symbol}']['last_price']\n",
    "    df3.at[inedx_counter, 'ltp'] = ltp\n",
    "#     print(one_symbol)    \n",
    "#     print(ltp)\n",
    "    inedx_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-19T06:55:49.744040Z",
     "start_time": "2021-06-19T05:29:17.693138Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_loss_list =[]\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for i in tqdm(range(18)):\n",
    "    this_model = f'./best_model_multi{i+1}.pt'\n",
    "    this_total_loss = 0.0\n",
    "    model = torch.load(this_model, map_location=torch.device('cpu'))\n",
    "    \n",
    "    inedx_counter = 0\n",
    "    df3['loss'] = 0.0\n",
    "    for one_inst in tqdm(df3.inst.astype(dtype='int32')):\n",
    "        _, val_data_ip = get_data2(one_inst)\n",
    "        this_loss = plot_and_loss(model, val_data_ip, 1, one_inst)\n",
    "        this_total_loss+=this_loss\n",
    "        df3.at[inedx_counter, 'loss'] = this_loss\n",
    "        inedx_counter+=1\n",
    "    print(this_model)\n",
    "    print(this_total_loss)\n",
    "        \n",
    "    model_loss_list.append({'model':this_model,'this_total_loss':this_total_loss})\n",
    "    \n",
    "model_loss_list_edf = pd.DataFrame(model_loss_list)\n",
    "model_loss_list_edf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-19T07:01:52.203907Z",
     "start_time": "2021-06-19T06:57:35.025268Z"
    }
   },
   "outputs": [],
   "source": [
    "this_model = f'./best_model_multi7.pt'\n",
    "this_total_loss = 0.0\n",
    "model = torch.load(this_model, map_location=torch.device('cpu'))\n",
    "\n",
    "inedx_counter = 0\n",
    "df3['loss'] = 0.0\n",
    "for one_inst in tqdm(df3.inst.astype(dtype='int32')):\n",
    "    _, val_data_ip = get_data2(one_inst)\n",
    "    this_loss = plot_and_loss(model, val_data_ip, 1, one_inst)\n",
    "    df3.at[inedx_counter, 'loss'] = this_loss\n",
    "    inedx_counter+=1\n",
    "\n",
    "print(this_model)\n",
    "print(this_total_loss)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.matshow(df3.corr())\n",
    "plt.show()\n",
    "df3['ltp_by_loss'] = df3['ltp']/df3['loss']\n",
    "# df3[['ltp_by_loss']]\n",
    "df3['ltp_by_lossx10'] = df3['ltp_by_loss']*20\n",
    "df3['lossx10'] = df3['loss']*20\n",
    "df3[['ltp','lossx10','ltp_by_lossx10']].plot()\n",
    "ax = df3[['ltp','lossx10','ltp_by_lossx10']].plot.hist(bins=100, alpha=0.3)\n",
    "df3[df3.ltp_by_loss > 180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-19T07:01:52.975911Z",
     "start_time": "2021-06-19T07:01:52.393656Z"
    }
   },
   "outputs": [],
   "source": [
    "this_model = f'./best_model_multi3.pt'\n",
    "this_total_loss = 0.0\n",
    "model = torch.load(this_model, map_location=torch.device('cpu'))\n",
    "\n",
    "inedx_counter = 0\n",
    "df3['loss'] = 0.0\n",
    "for one_inst in tqdm(df3.inst.astype(dtype='int32')):\n",
    "    _, val_data_ip = get_data2(one_inst)\n",
    "    this_loss = plot_and_loss(model, val_data_ip, 1, one_inst)\n",
    "    df3.at[inedx_counter, 'loss'] = this_loss\n",
    "    inedx_counter+=1\n",
    "\n",
    "print(this_model)\n",
    "print(this_total_loss)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.matshow(df3.corr())\n",
    "plt.show()\n",
    "df3['ltp_by_loss'] = df3['ltp']/df3['loss']\n",
    "# df3[['ltp_by_loss']]\n",
    "df3['ltp_by_lossx10'] = df3['ltp_by_loss']*20\n",
    "df3['lossx10'] = df3['loss']*20\n",
    "df3[['ltp','lossx10','ltp_by_lossx10']].plot()\n",
    "ax = df3[['ltp','lossx10','ltp_by_lossx10']].plot.hist(bins=100, alpha=0.3)\n",
    "df3[df3.ltp_by_loss > 180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-19T10:19:20.541518Z",
     "start_time": "2021-06-19T10:19:20.377117Z"
    }
   },
   "outputs": [],
   "source": [
    "df3.to_excel('./df3.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-19T14:37:22.679724Z",
     "start_time": "2021-06-19T14:37:22.674147Z"
    }
   },
   "outputs": [],
   "source": [
    "import QuantConnect_Reserved"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "462px",
    "left": "995px",
    "right": "20px",
    "top": "119px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
